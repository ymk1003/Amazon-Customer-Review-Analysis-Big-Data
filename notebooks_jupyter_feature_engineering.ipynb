{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "11c4e6f1-747d-4605-8697-9acd1955ed68",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gs://qst843-project/amazon_reviews_2023/silver/reviews_combined_compact\n",
      "gs://qst843-project/amazon_reviews_2023/silver/meta_combined_compact\n"
     ]
    }
   ],
   "source": [
    "# Spark init. / Data Path\n",
    "from pyspark.sql import SparkSession\n",
    "bucket = spark._jsc.hadoopConfiguration().get(\"fs.gs.system.bucket\")\n",
    "review_path = \"gs://\" + bucket + \"/amazon_reviews_2023/silver/reviews_combined_compact\"\n",
    "meta_path = \"gs://\" + bucket + \"/amazon_reviews_2023/silver/meta_combined_compact\"\n",
    "print(review_path)\n",
    "print(meta_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f527ab59-d7b4-4755-af94-1c09ad7ad5e2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Load Cleaned Data (Review & Meta)\n",
    "df_review = spark.read.option(\"recursiveFileLookup\", \"true\").parquet(review_path)\n",
    "df_meta = spark.read.option(\"recursiveFileLookup\", \"true\").parquet(meta_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "12c7d270-cddf-4fda-a54f-53c3acbddac1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Rename / Drop Duplicate Field Names (\"title\", \"category_name\")\n",
    "df_review = df_review.withColumnRenamed(\"title\", \"review_title\")\n",
    "df_meta = df_meta.withColumnRenamed(\"title\", \"product_name\")\n",
    "df_meta = df_meta.drop(\"category_name\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e28067b0-ece4-4d94-af27-79a01f205d4f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Join Review & Meta Data into a Single df\n",
    "df = df_review.join(\n",
    "    df_meta,\n",
    "    on=\"parent_asin\",\n",
    "    how=\"left\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6f0cd8d3-e244-4a7b-a5a3-6c8144c3a5c4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_sampled = df.sample(withReplacement=False, fraction=0.0002, seed=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7722e72b-aad1-43b9-ab9f-94b6f559cd43",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- parent_asin: string (nullable = true)\n",
      " |-- user_id: string (nullable = true)\n",
      " |-- timestamp: timestamp (nullable = true)\n",
      " |-- rating: integer (nullable = true)\n",
      " |-- review_title: string (nullable = true)\n",
      " |-- text: string (nullable = true)\n",
      " |-- helpful_vote: integer (nullable = true)\n",
      " |-- verified_purchase: boolean (nullable = true)\n",
      " |-- review_image: boolean (nullable = true)\n",
      " |-- category_name: string (nullable = true)\n",
      " |-- product_name: string (nullable = true)\n",
      " |-- main_category: string (nullable = true)\n",
      " |-- categories: array (nullable = true)\n",
      " |    |-- element: string (containsNull = true)\n",
      " |-- price: double (nullable = true)\n",
      " |-- features: array (nullable = true)\n",
      " |    |-- element: string (containsNull = true)\n",
      " |-- description: array (nullable = true)\n",
      " |    |-- element: string (containsNull = true)\n",
      " |-- average_rating: double (nullable = true)\n",
      " |-- rating_number: long (nullable = true)\n",
      " |-- brand: string (nullable = true)\n",
      " |-- store: string (nullable = true)\n",
      " |-- product_image: boolean (nullable = true)\n",
      " |-- product_video: boolean (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_sampled.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6de79ce-689f-4769-8ae5-3401e778b4f2",
   "metadata": {},
   "source": [
    "product_image\n",
    "product_video\n",
    "verified_purchase\n",
    "review_image\n",
    "price\n",
    "helpful_vote\n",
    "\n",
    "rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "73effe85-98cf-4e55-8af5-35e8c926a47c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import VectorAssembler\n",
    "feature_cols = [\n",
    "    'product_image',\n",
    "    'product_video',\n",
    "    'verified_purchase',\n",
    "    'review_image',\n",
    "    'price',\n",
    "    'helpful_vote'\n",
    "]\n",
    "\n",
    "df_clean = df_sampled.na.drop(subset=feature_cols)\n",
    "\n",
    "va = VectorAssembler(\n",
    "    inputCols=feature_cols,\n",
    "    outputCol=\"features_ml\"\n",
    "    # default handleInvalid=\"error\", but now there are no nulls left\n",
    ")\n",
    "\n",
    "df_vec = va.transform(df_clean)\n",
    "df_vec = df_vec.select(\"features_ml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "946e1895-14e1-4b25-af51-6d44dcc7f6a9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 25:>                                                         (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------------------+\n",
      "|features_ml                 |\n",
      "+----------------------------+\n",
      "|[1.0,1.0,0.0,0.0,72.85,0.0] |\n",
      "|[1.0,1.0,1.0,0.0,8.49,0.0]  |\n",
      "|[1.0,1.0,1.0,0.0,13.99,0.0] |\n",
      "|[1.0,1.0,0.0,0.0,18.94,0.0] |\n",
      "|[1.0,1.0,1.0,0.0,23.56,0.0] |\n",
      "|[1.0,1.0,1.0,0.0,8.56,0.0]  |\n",
      "|[1.0,0.0,1.0,0.0,29.99,0.0] |\n",
      "|[1.0,1.0,1.0,0.0,54.0,0.0]  |\n",
      "|[1.0,1.0,1.0,0.0,54.0,0.0]  |\n",
      "|[1.0,0.0,1.0,1.0,94.3,0.0]  |\n",
      "|[1.0,1.0,1.0,0.0,17.99,0.0] |\n",
      "|[1.0,1.0,1.0,0.0,17.99,31.0]|\n",
      "|[1.0,1.0,1.0,0.0,17.99,0.0] |\n",
      "|[1.0,0.0,1.0,0.0,8.49,0.0]  |\n",
      "|[1.0,0.0,1.0,0.0,44.83,0.0] |\n",
      "|[1.0,1.0,1.0,0.0,5.29,0.0]  |\n",
      "|[1.0,1.0,1.0,0.0,55.25,0.0] |\n",
      "|[1.0,1.0,1.0,0.0,16.0,0.0]  |\n",
      "|[1.0,1.0,1.0,0.0,5.1,6.0]   |\n",
      "|[1.0,0.0,1.0,0.0,4.38,1.0]  |\n",
      "+----------------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df_vec.show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa040974-3fc4-4925-b96d-e072d68ea7c6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PySpark",
   "language": "python",
   "name": "pyspark"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}